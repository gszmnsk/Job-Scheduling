{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a366b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every job has its tasks that have to be done on a specific machine \n",
    "# We have 2 machines and 3 jobs\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from collections import deque\n",
    "import random\n",
    "from collections import deque\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "jobs_data = [ # task = (machine_id, processing_time)\n",
    "    [(0, 3), (1, 2)],  # Job_0\n",
    "        [(0, 2),  (1, 4)],  # Job_1\n",
    "        [(0, 4), (1, 3)]  # Job_2\n",
    "]\n",
    "\n",
    "machines_count = 2\n",
    "all_machines = range(machines_count)\n",
    "NUMBER_OF_CLASSES = 2\n",
    "\n",
    "machine_ids = []\n",
    "processing_time = []\n",
    "for job in jobs_data:\n",
    "    for task in job:\n",
    "        machine_ids.append(task[0]) #labels\n",
    "        processing_time.append(task[1]) #features\n",
    "\n",
    "#labels to vectors\n",
    "machine_ids = np_utils.to_categorical(machine_ids, NUMBER_OF_CLASSES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22b434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd279af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobShop:\n",
    "    # This class is the environment of Job shop problem\n",
    "\n",
    "    #bool_generate_random_jssp = None\n",
    "    number_job = None\n",
    "    number_machine = None\n",
    "    number_features = None\n",
    "\n",
    "    # the lower limit of one position of job 's processing time.\n",
    "    #time_low = None\n",
    "    # the upper limit of one position of job 's processing time.\n",
    "    #time_high = None\n",
    "\n",
    "    # Matrix of processing time, M_processing_time[i,j] is the processing time of job i 's position j.\n",
    "    M_processing_time = np.array([[18, 20, 21, 17], [18, 26, 15, 16], [17, 18, 27, 23], [18, 21, 25, 15], [22, 29, 28, 21]])\n",
    "    \n",
    "    # Matrix of processing time, M_processing_order[i,j] is the machine restrain of job i 's position j.\n",
    "    # (0,1,2,3) - machine ids\n",
    "    M_processing_order = np.array([[1, 3, 0, 2], [0, 2, 1, 3], [3, 1, 2, 0], [1, 3, 0, 2], [0, 1, 2, 3]]) \n",
    "    \n",
    "    M_start_time = None\n",
    "    M_end_time = None\n",
    "    X_schedule_plan = None\n",
    "    schedule_line = None\n",
    "    \n",
    "    def Get_Possible_Job_Position(self): \n",
    "        # ergodic the schedule_line, and return the possible position to produce of jobs\n",
    "\n",
    "        job_position_list = [0 for i in range(self.number_job)] # generuje listę zer o długości number_of_jobs\n",
    "        for job_id, job_position in self.schedule_line: # schedule_line = [[action_1, job_position_1], [action_2, job_position_2],...]\n",
    "            if job_position < self.number_machine-1:\n",
    "                job_position_list[job_id] = job_position+1\n",
    "            else:\n",
    "                job_position_list[job_id] = -1\n",
    "\n",
    "        return [[i, job_position_list[i]] for i in range(len(job_position_list))]\n",
    "\n",
    "\n",
    "    def GetFeature(self, job_id, job_position):\n",
    "        # get the feature of one position of one job \n",
    "        # readers can change the feature to get a more powerful model \n",
    "\n",
    "        # raw features\n",
    "        machine_id = self.M_processing_order[job_id, job_position]\n",
    "        job_time_need = np.sum(self.M_processing_time, axis=1)\n",
    "        current_time_use = self.M_processing_time[job_id, job_position]\n",
    "\n",
    "        machine_endtime = np.max(self.M_end_time, axis=1)\n",
    "        job_endtime = np.sum(self.M_processing_time[job_id, :job_position])\n",
    "        job_alltime = np.sum(self.M_processing_time[job_id, :])\n",
    "\n",
    "        if job_position == 0:\n",
    "            frac_currentend_othermachineave = 0.5\n",
    "            frac_currentend_otherjobave = 0.5\n",
    "            frac_currentendplusthisposition_othermachineave = 1\n",
    "            schedule_finish_station = 0\n",
    "\n",
    "            frac_jobposition_jobtime = 1\n",
    "            frac_jobposition_totaltime = 1\n",
    "        else:\n",
    "            frac_currentend_othermachineave = (\n",
    "                0.1 + machine_endtime[machine_id]) / (0.1 + np.average(machine_endtime))\n",
    "            \n",
    "            frac_currentendplusthisposition_othermachineave = (\n",
    "                machine_endtime[machine_id] + current_time_use) / np.average(machine_endtime)\n",
    "            \n",
    "            schedule_finish_station = np.count_nonzero(\n",
    "                self.M_end_time)/self.number_machine/self.number_job\n",
    "\n",
    "            frac_currentend_otherjobave = (0.1+job_endtime) / (0.1+job_alltime)\n",
    "            frac_jobposition_jobtime = current_time_use/job_time_need[job_id]\n",
    "            frac_jobposition_totaltime = current_time_use/np.sum(job_time_need)\n",
    "\n",
    "        # feature choose\n",
    "        features = []\n",
    "        # current features\n",
    "        features.append(frac_currentend_othermachineave)\n",
    "        features.append(frac_currentend_otherjobave)\n",
    "\n",
    "        # features.append(frac_currentendplusthisposition_othermachineave)\n",
    "        # features.append(schedule_finish_station)\n",
    "        # # stable features\n",
    "        # features.append(frac_jobposition_jobtime)\n",
    "        # features.append(frac_jobposition_totaltime)\n",
    "\n",
    "        self.number_features = len(features)\n",
    "\n",
    "        if job_position == -1:\n",
    "            features = [-1] * self.number_features\n",
    "\n",
    "        return features\n",
    "    \n",
    "    def Get_Features(self, possible_job_position):\n",
    "        # return the features of current state\n",
    "\n",
    "        featrues = []\n",
    "        for job_id, job_position in possible_job_position:\n",
    "            f_item = self.GetFeature(job_id, job_position)\n",
    "            featrues.append(f_item)\n",
    "\n",
    "        return featrues\n",
    "    \n",
    "    def MeasurementAction(self, action_history):\n",
    "        # measurement the action and return the makespan\n",
    "\n",
    "        M_start_time = np.zeros((self.number_machine, self.number_job))\n",
    "        M_end_time = np.zeros((self.number_machine, self.number_job))\n",
    "\n",
    "        timeline_machine = np.zeros((self.number_machine), dtype=int)\n",
    "        index_machine = np.zeros((self.number_machine), dtype=int)\n",
    "        \n",
    "        timeline_job = np.zeros((self.number_job), dtype=int)\n",
    "        index_job = np.zeros((self.number_job), dtype=int)\n",
    "        \n",
    "        X_schedule_plan = np.zeros(\n",
    "            (self.number_machine, self.number_job, 2), dtype=int)\n",
    "        \n",
    "        # job_id == action - the job chosen to process\n",
    "        for job_id, job_position in action_history: #action_history == schedule_line ==[[action_1, job_pos_1], ...]\n",
    "            \n",
    "            # M_processing_order = np.array([[1 <- machine_id, 3, 0, 2], ...]\n",
    "            # machine_id - numer maszyny na której musi zostać wykonany dany task z joba\n",
    "            machine_id = self.M_processing_order[job_id, job_position] \n",
    "            # aktualny czas od którego rozpoczynam\n",
    "            current_start_time = max(timeline_machine[machine_id], timeline_job[job_id])\n",
    "            \n",
    "            # aktualizuje aktualny czas zakończenia zadania, start_time + czas potrzebny do wykonania zadania\n",
    "            current_end_time = current_start_time + \n",
    "                self.M_processing_time[job_id, job_position]\n",
    "                \n",
    "            #aktualizuje timeline maszyny i pracy\n",
    "            timeline_machine[machine_id], timeline_job[job_id] = current_end_time, current_end_time \n",
    "            \n",
    "            # index oznaczający kolejność danego joba na danej maszynie\n",
    "            current_index = index_machine[machine_id] # index_machine == array([0,1,0,0]) <- job ma pozycję numer 2 \n",
    "                                                                                            # na maszynie numer 2\n",
    "            M_start_time[machine_id, current_index] = current_start_time\n",
    "            M_end_time[machine_id, current_index] = current_end_time\n",
    "            \n",
    "            # Tworzy harmonogram, w którym wstawia [job_id, job_position] na miejsce\n",
    "            X_schedule_plan[machine_id, current_index, :] = [job_id, job_position] \n",
    "            \n",
    "            index_machine[machine_id] += 1 # idziemy do następnej maszyny\n",
    "            \n",
    "            index_job[job_id] += 1 # idziemy do następnej roboty\n",
    "\n",
    "        self.M_start_time = M_start_time\n",
    "        self.M_end_time = M_end_time # Macierz, której wierszami są poszczególne maszyny, a kolumnami - jobs, prace\n",
    "        self.X_schedule_plan = X_schedule_plan \n",
    "        return np.max(M_end_time) # zwraca ile trwała cała praca (makespan)\n",
    "\n",
    "     def Step(self, action=None):\n",
    "        # be called in main function\n",
    "        # input action and return state score and done\n",
    "        # action: choose a job to process.\n",
    "        # state:\n",
    "\n",
    "        done = False\n",
    "        if action == None:\n",
    "            #self.MeasurementAction(self.schedule_line)\n",
    "            possible_job_position = self.Get_Possible_Job_Position()\n",
    "            state = np.array(self.Get_Features(possible_job_position))\n",
    "            score = 0\n",
    "            \n",
    "        else:\n",
    "            job_position_list = [0 for i in range(self.number_job)]\n",
    "            for job_id, job_position in self.schedule_line:\n",
    "                if job_position < self.number_machine-1:\n",
    "                    job_position_list[job_id] = job_position+1\n",
    "                else:\n",
    "                    job_position_list[job_id] = -1\n",
    "                    \n",
    "            if job_position_list[action] == -1:  # action - number of the job to do\n",
    "                done = True\n",
    "                # Generate random action\n",
    "                canchoose = [[i, job_position_list[i]] for i in range(\n",
    "                    self.number_job) if job_position_list[i] != -1]\n",
    "                action = canchoose[0]\n",
    "                # Generate action from a state with DQAgent.act(state) function\n",
    "            else:\n",
    "                action = [action, job_position_list[action]]\n",
    "\n",
    "            self.schedule_line.append(action)\n",
    "            self.MeasurementAction(self.schedule_line)\n",
    "            # self.PlotResult()\n",
    "            score = np.max(self.M_end_time)\n",
    "\n",
    "            possible_job_position = self.Get_Possible_Job_Position()\n",
    "            state = np.array(self.Get_Features(possible_job_position))\n",
    "\n",
    "        state = [np.reshape(state[i], (1, 2,)) for i in range(self.number_job)]\n",
    "\n",
    "        return state, score, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18088298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_schedule_plan = np.zeros(\n",
    "            (4, 5, 2), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0f82711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_schedule_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076aceab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQAgent:\n",
    "\n",
    "\n",
    "  def __init__(self):\n",
    "        MEMORY_SIZE = 2000 # number of steps from which we take the random sampling <- that's the batch we are going to train the NN off of\n",
    "        MIN_MEMORY_SIZE = 1000  # Minimum number of steps in a memory to start training\n",
    "        BATCH_SIZE = 64  # How many steps (samples) to use for training\n",
    "        UPDATE_TARGET_EVERY = 5  # Terminal states (end of episodes)\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.number_job = number_job\n",
    "        self.number_feature = number_feature\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 0.9  # exploration rate\n",
    "\n",
    "        # Main model which we .fit() the model for every step the agent takes\n",
    "        self.model = self.create_model()\n",
    "\n",
    "        # Target network which we .predict() every step\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "        # Reupdating the model weights every some number of steps, not allowing the model to make predition every step, instead for example every 5 episodes or so\n",
    "        # In order to have some kind of stability, so the model can actually learn and not overfit to \n",
    "        self.target_model.set_weights(self.model.get_weights()) \n",
    "\n",
    "        # An array with last n steps for training\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        # Used to count when to update target network with main network's weights\n",
    "        self.target_update_counter = 0\n",
    "\n",
    "  def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential(name='basic_model')\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=0.0005))\n",
    "        return model\n",
    "\n",
    "  def update_memory(self, state, action, reward, next_state, done):\n",
    "        # remember the information of current step\n",
    "        # done - information wether or not it was done\n",
    "        self.memory.append((current_state, action, reward, next_state, done))\n",
    "\n",
    "  def act(self, state):\n",
    "        # Agent takes a random action\n",
    "        # choose a job to process in current state\n",
    "\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "  def train(self, terminal_state, step):\n",
    "\n",
    "    # checking if there are any samples in memory, so we can start to train\n",
    "    if len(self.memory) < MIN_MEMORY_SIZE:\n",
    "        return # if not we aint do nothin\n",
    "\n",
    "    # Setting the minibatch if there is enough samples in a memory\n",
    "    minibatch =  random.sample(self.memory, BATCH_SIZE)\n",
    "\n",
    "    for index, (current_state, action, reward, next_state, done) in enumerate(minibatch):\n",
    "\n",
    "      \n",
    "\n",
    "  def get_q_values()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
